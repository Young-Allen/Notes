
## 一、笔记

① 衡量模型预测出来的值 h(θ) 与真实值 y 之间差异的函数叫做代价函数 J(θ)。

② 代价函数值越小说明模型和参数越符合训练样本 (x, y) 对应的模型。

③ 代价函数是用来找到假设函数的最优解的，将求假设函数问题转换为求代价函数问题。

④ 我们根据[平方误差代价函数](https://www.zhihu.com/search?q=%E5%B9%B3%E6%96%B9%E8%AF%AF%E5%B7%AE%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1623023066%7D)来求假设函数的最优解。

⑤ 平方误差代价函数就是将实际数据给出的值与我们拟合出的对应值做差，然后再取平方，平方误差代价函数能表示拟合出的模型对应的值与实际值的差距。

![](assets/v2-7670ed01829d080bf02c4ea56a066543_720w.png)

⑥ 例如，假设函数为：$h_{\theta}(x) = \theta_{0}+\theta_{1} x$h\_{\\theta}(x) = \\theta\_{0}+\\theta\_{1} x，最简单的单一参数 ( 有θ1，无θ0，即θ0=0 )，当θ1已知时，假设函数的模型就已知，不同的输入 X 值对应出不同的假设函数值h(x)。

![](assets/v2-4be2ebe63dde64720154b068398651b4_720w.png)

④ 代价函数 J(θ0，θ1) 为下面的式子：

> 1\. 式子前面乘以1/2，是因为后面要用梯度下降法，要求导，这样求导多出的乘2就和二分之一抵消了，一个简化后面计算的技巧，为了简便计算。

![](assets/v2-7485602e972ae45065b76db46318407e_720w.png)

⑤ 最优解即为代价函数的最小值，根据以上公式可得代价函数的图像(即J(θ1)关于θ1的[变化曲线](https://www.zhihu.com/search?q=%E5%8F%98%E5%8C%96%E6%9B%B2%E7%BA%BF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1623023066%7D))。

> 1\. x、y 都可根据数据得到，而 θ 的改变，代价函数 J 的值就会相应的发生变化，即 x、y、m都是常数，J 是关于 θ 的函数。  
> 2\. 下图可以看到代价函数(J(θ1))的确有最小值，代价[函数最小值](https://www.zhihu.com/search?q=%E5%87%BD%E6%95%B0%E6%9C%80%E5%B0%8F%E5%80%BC&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A1623023066%7D)就是θ1(横坐标)为1的时候。

![](assets/v2-5ad9170ad5e62b174a2ee4c7410b4532_720w.png)

⑥ 两个参数的时候，代价函数是三维图像(X轴是θ0、Y轴是θ1、Z轴是代价函数J(θ0、θ1))，高度为代价函数的值，它仍然有着最小值。

![](assets/v2-9826e197a88fa917f468fe40ac193947_720w.png)

⑦ 更多参数的时候无法直观可视化，但是原理都是相似的，都是取代价函数的最小值为模型与数据的分布情况最匹配。

⑧ 对于回归问题，我们就可以将求出最佳的拟合函数问题转换为代价函数的最小值的问题。
