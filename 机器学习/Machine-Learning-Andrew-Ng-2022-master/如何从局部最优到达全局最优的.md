在优化问题中，我们通常希望寻找全局最优解，而不仅仅是局部最优解。但是，在某些情况下，梯度下降等优化算法会陷入局部最优解，使得无法达到全局最优解。那么如何从局部最优跳出，达到全局最优呢？

以下是几种常见的从局部最优到达全局最优的方法：

1. 随机重启动（Random Restart）：这种方法可以随机地重新初始化模型参数并重新运行多次，以期望在多次运行后可以尝试不同的初始点，并找到全局最优解。
    
2. 模拟退火（Simulated Annealing）：这种方法通过降低概率接受更劣解决方案的方式来避免局部最优解的干扰。使用类似于物理中退火的温度下降过程中的方法来提高溢出局部极小值的概率。
    
3. 遗传算法（Genetic Algorithm）：这种方法利用自然选择、变异和交叉等遗传操作产生新的解决方案，并将它们与原有的解决方案进行竞争，以找到最优解。每次操作都会随机产生新的解决方案，并根据某种适应度函数对它们进行评估，保留适应度最高的解决方案，然后将其与其他方案进一步交叉和变异。
    
4. 正则化（Regularization）：这种方法通过对损失函数加上正则化项来使得最终的解决方案更加平滑。正则化可以有效地防止过拟合，从而减少局部最优解的干扰。
    
5. 神经网络架构搜索（Neural Architecture Search）：这种方法可以使用神经网络架构搜索算法，自动地发现最优的网络结构和超参数，以帮助避免陷入局部最优解。
    

总之，在实际应用中，常用的方法是多次运行梯度下降算法，并通过以上提到的方法进一步修正和完善，以期望找到全局最优解。